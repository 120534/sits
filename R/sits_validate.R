
#' @title validate temporal patterns
#' @name sits_validate
#' @author Victor Maus, \email{vwmaus1@@gmail.com}
#' @author Gilberto Camara, \email{gilberto.camara@@inpe.br}
#' @author Rolf Simoes, \email{rolf.simoes@@inpe.br}
#'
#' @description Splits the set of time series into training and validation and
#' compute accuracy metrics. The function uses stratified sampling and a simple
#' random sampling for each stratum. For each data partition this function
#' performs a TWDTW analysis and returns the Overall Accuracy, User's Accuracy,
#' Produce's Accuracy, error matrix (confusion matrix), and a \code{\link[base]{data.frame}}
#' with the classification (Predicted), the reference classes (Reference),
#' and the results of the TWDTW analysis.
#'
#' @param  data.tb       a SITS tibble
#' @param  bands         the bands used for classification
#' @param  method        method to create patterns ("gam", "dendogram" or "centroids")
#' @param  times         number of partitions to create.
#' @param  perc          the percentage of data that goes to training.
#' @param  conversion.lst a conversion of label names for the classes (optional))
#' @param  freq          int - the interval in days for the estimates to be generated (for "gam" method)
#' @param  from          starting date of the estimate in month-day (for "gam" method)
#' @param  to            end data of the estimated in month-day (for "gam" method)
#' @param  formula       the formula to be applied in the estimate (for "gam" method)
#' @param  n_clusters    the maximum number of clusters to be identified (for clustering methods)
#' @param  min_clu_perc  the minimum percentagem of valid cluster members, with reference to the total number of samples (for clustering methods)
#' @param  show          show the results of the clustering algorithm? (for clustering methods)
#' @return patterns.tb   a SITS table with the patterns
#' @export
sits_validate <- function (data.tb, bands = NULL, method = "gam", times = 100, perc = 0.1,
                           conversion.lst = NULL, freq = 8, from = NULL, to = NULL, formula = y ~ s(x),
                           n_clusters = 2, min_clu_perc = 0.10, show = FALSE){

     # does the input data exist?
     ensurer::ensure_that(data.tb, !purrr::is_null(.),
                          err_desc = "sits_validate: input data not provided")
     # are the bands to be classified part of the input data?
     ensurer::ensure_that(data.tb, !(FALSE %in% bands %in% (sits_bands(.))),
                          err_desc = "sits_validate: invalid input bands")

     # what are the labels of the samples?
     labels <- dplyr::distinct (data.tb, label)

     #extract the bands to be included in the patterns
     if (!purrr::is_null (bands))
          bands <- sits_bands (data.tb)
     else
          data.tb <- sits_select(data.tb, bands)

     # if the conversion list is NULL, create an identity list
     if (purrr::is_null(conversion.lst)) {
          conversion.lst <- tibble::lst()
          for (i in 1:nrow(labels)) {
               lab <- as.character(labels[i,"label"])
               conversion.lst [lab] <- lab
          }
     }
     else {
          ensurer::ensure_that(conversion.lst, !(FALSE %in% names(.) %in% unlist(labels[,1])),
                               err_desc = "conversion list does not match labels of the data")
     }
     # create partitions different splits of the input data
     partitions.lst <- .sits_create_partitions (data.tb, times, perc)
     # create a vector to store the result of the predictions
     pred.vec <- c()
     # create a vector to store the references
     ref.vec  <- c()

     # for each partition, fill the prediction and reference vectors
     for (i in 1:length(partitions.lst)){
          # retrieve the extracted partition
          p <- partitions.lst[[i]]
          # use the extracted partition to create the patterns
          patterns.tb <- sits_patterns(p, method, freq = freq, from = from, to = to, formula = formula,
                                       n_clusters = n_clusters, min_clu_perc = min_clu_perc, show = show)
          # use the rest of the data for classification
          non_p.tb <- dplyr::anti_join(data.tb, p,
                                by = c("longitude", "latitude", "start_date",
                                       "end_date", "label", "coverage"))
          # classify each row of the data
          for (i in 1:nrow(non_p.tb)) {
               # do the classification of a single time series
               results.tb  <- sits_TWDTW (non_p.tb[i,], patterns.tb, bands)
               # find out the alignment associated to the minimum distance
               i <- which.min(results.tb$alignments[[1]]$distance)
               # find the predicted label
               pred <- results.tb$alignments[[1]][i,"label"]
               # remove the numeric qualifier for the labels (generated by clustering)
               # for example, "Forest_1" becomes "Forest"
               if (stringr::str_detect(pred,"[0-9]"))
                    pred <- stringr::str_extract(pred,"[A-Za-z]+|[^_$]")
               # find the reference label
               ref  <- as.character(results.tb$label)
               # increase the prediction and reference vectors
               # the names of the labels are converted (optional)
               pred.vec[length(pred.vec) + 1] <- conversion.lst[[pred]]
               ref.vec [length(ref.vec)  + 1] <- conversion.lst[[ref]]
          }
     }
     # get the error matrix (caret methods\)
     #error.matrix = caret::confusionMatrix(data=pred.vec, reference=ref.vec)
     assess <- rfUtilities::accuracy(pred.vec, ref.vec)

     # error.matrix = table(Predicted=data$Predicted, Reference=data$Reference)
     # UA = diag(error.matrix) / rowSums(error.matrix)
     # PA = diag(error.matrix) / colSums(error.matrix)
     # O  = sum(diag(error.matrix)) / sum(rowSums(error.matrix))
     # list(OverallAccuracy=O, UsersAccuracy=UA, ProducersAccuracy=PA, ErrorMatrix=error.matrix, data=data)

     return (assess)
}
#' @title Create partitions of a data set
#' @name  sits_create_partitions
#' @author Rolf Simoes, \email{rolf.simoes@@inpe.br}
#'
#' @description Create a list of partitions of a SITS table, based on a percentage and
#' a number of iterations
#'
#' @param data.tb a SITS table to be partitioned
#' @param times   number of iterations
#' @param perc    percentagem of original data to be extracted
#' @export
.sits_create_partitions <- function (data.tb, times, perc) {

     # create a list to store the partitions
     partitions.lst <- tibble::lst()

     # iterate and create the partitions
     for (i in 1:times){
          partitions.lst [[i]] <- sits_label_perc (data.tb, perc)
     }
     return (partitions.lst)
}
